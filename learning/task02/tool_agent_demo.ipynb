{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv,find_dotenv\n",
    "# 加载环境变量\n",
    "load_dotenv(find_dotenv())\n",
    "# 从环境变量中读取api_key\n",
    "api_key = os.getenv('ZHIPU_API_KEY')\n",
    "base_url = os.getenv('ZHIPU_BASE_URL')\n",
    "chat_model = os.getenv('ZHIPU_CHAT_MODEL')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我是一个名为 ChatGLM 的人工智能助手，是基于清华大学 KEG 实验室和智谱 AI 公司于 2024 年共同训练的语言模型开发的。我的任务是针对用户的问题和要求提供适当的答复和支持。"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from pydantic import Field  # 导入Field，用于Pydantic模型中定义字段的元数据\n",
    "from llama_index.core.llms import (\n",
    "    CustomLLM,\n",
    "    CompletionResponse,\n",
    "    LLMMetadata,\n",
    ")\n",
    "from llama_index.core.embeddings import BaseEmbedding\n",
    "from llama_index.core.llms.callbacks import llm_completion_callback\n",
    "from typing import List, Any, Generator\n",
    "\n",
    "\n",
    "# 定义OurLLM类，继承自CustomLLM基类\n",
    "class OurLLM(CustomLLM):\n",
    "    api_key: str = Field(default=api_key)\n",
    "    base_url: str = Field(default=base_url)\n",
    "    model_name: str = Field(default=chat_model)\n",
    "    client: OpenAI = Field(default=None, exclude=True)  # 显式声明 client 字段\n",
    "\n",
    "    def __init__(self, api_key: str, base_url: str, model_name: str = chat_model, **data: Any):\n",
    "        super().__init__(**data)\n",
    "        self.api_key = api_key\n",
    "        self.base_url = base_url\n",
    "        self.model_name = model_name\n",
    "        self.client = OpenAI(api_key=self.api_key, base_url=self.base_url)  # 使用传入的api_key和base_url初始化 client 实例\n",
    "\n",
    "    @property\n",
    "    def metadata(self) -> LLMMetadata:\n",
    "        \"\"\"Get LLM metadata.\"\"\"\n",
    "        return LLMMetadata(\n",
    "            model_name=self.model_name,\n",
    "        )\n",
    "\n",
    "    @llm_completion_callback()\n",
    "    def complete(self, prompt: str, **kwargs: Any) -> CompletionResponse:\n",
    "        response = self.client.chat.completions.create(model=self.model_name, messages=[{\"role\": \"user\", \"content\": prompt}])\n",
    "        if hasattr(response, 'choices') and len(response.choices) > 0:\n",
    "            response_text = response.choices[0].message.content\n",
    "            return CompletionResponse(text=response_text)\n",
    "        else:\n",
    "            raise Exception(f\"Unexpected response format: {response}\")\n",
    "\n",
    "    @llm_completion_callback()\n",
    "    def stream_complete(\n",
    "        self, prompt: str, **kwargs: Any\n",
    "    ) -> Generator[CompletionResponse, None, None]:\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=self.model_name,\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            stream=True\n",
    "        )\n",
    "\n",
    "        try:\n",
    "            for chunk in response:\n",
    "                chunk_message = chunk.choices[0].delta\n",
    "                if not chunk_message.content:\n",
    "                    continue\n",
    "                content = chunk_message.content\n",
    "                yield CompletionResponse(text=content, delta=content)\n",
    "\n",
    "        except Exception as e:\n",
    "            raise Exception(f\"Unexpected response format: {e}\")\n",
    "\n",
    "llm = OurLLM(api_key=api_key, base_url=base_url, model_name=chat_model)\n",
    "\n",
    "\n",
    "response = llm.stream_complete(\"你是谁？\")\n",
    "for chunk in response:\n",
    "    print(chunk, end=\"\", flush=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Running step 1a2f262b-df5c-4e51-b374-7cf599ceffff. Step input: 20+（2*4）等于多少？使用工具计算每一步\n",
      "\u001b[1;3;38;5;200mThought: The user is asking to calculate the result of the expression 20 + (2 * 4) using tools. I need to break down the expression into parts and calculate each part using the appropriate tools.\n",
      "Action: multiply\n",
      "Action Input: {'a': 2, 'b': 4}\n",
      "\u001b[0m\u001b[1;3;34mObservation: 8\n",
      "\u001b[0m> Running step d1da8b68-88dd-4f5b-a947-cb4419142397. Step input: None\n",
      "\u001b[1;3;38;5;200mThought: The user is asking to calculate the result of the expression 20 + (2 * 4) using tools. I need to break down the expression into parts and calculate each part using the appropriate tools.\n",
      "Action: multiply\n",
      "Action Input: {'a': 2, 'b': 4}\n",
      "\u001b[0m\u001b[1;3;34mObservation: 8\n",
      "\u001b[0m> Running step f2594fa7-417c-4985-9ef4-2cc459199a2b. Step input: None\n",
      "\u001b[1;3;38;5;200mThought: The next step is to add 20 to the result of 2 multiplied by 4.\n",
      "Action: add\n",
      "Action Input: {'a': 20, 'b': 8}\n",
      "\u001b[0m\u001b[1;3;34mObservation: 28\n",
      "\u001b[0m> Running step a93e4037-d45b-4313-8eef-606708e5b74a. Step input: None\n",
      "\u001b[1;3;38;5;200mThought: The user is asking to calculate the result of the expression 20 + (2 * 4) using tools. I have already calculated the multiplication part as 2 * 4 = 8. Now, I need to add 20 to this result.\n",
      "Action: add\n",
      "Action Input: {'a': 20, 'b': 8}\n",
      "\u001b[0m\u001b[1;3;34mObservation: 28\n",
      "\u001b[0m> Running step 0ecffbe0-7e62-462f-8c19-71ceae888617. Step input: None\n",
      "\u001b[1;3;38;5;200mThought: I can answer without using any more tools. I'll use the user's language to answer\n",
      "Answer: 20 + (2 * 4) = 28\n",
      "\u001b[0m20 + (2 * 4) = 28\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), \"..\", \"..\")))\n",
    "\n",
    "from llama_index.core.agent import ReActAgent\n",
    "from llama_index.core.tools import FunctionTool\n",
    "\n",
    "\n",
    "def multiply(a: float, b: float) -> float:\n",
    "    \"\"\"Multiply two numbers and returns the product\"\"\"\n",
    "    return a * b\n",
    "\n",
    "\n",
    "def add(a: float, b: float) -> float:\n",
    "    \"\"\"Add two numbers and returns the sum\"\"\"\n",
    "    return a + b\n",
    "\n",
    "\n",
    "multiply_tool = FunctionTool.from_defaults(fn=multiply)\n",
    "add_tool = FunctionTool.from_defaults(fn=add)\n",
    "\n",
    "\n",
    "def main():\n",
    "\n",
    "\n",
    "    # 创建ReActAgent实例\n",
    "    agent = ReActAgent.from_tools([multiply_tool, add_tool], llm=llm, verbose=True)\n",
    "\n",
    "    response = agent.chat(\"20+（2*4）等于多少？使用工具计算每一步\")\n",
    "\n",
    "    print(response)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Running step 81b4b980-b347-416d-9096-82fa5a86db5c. Step input: 纽约天气怎么样?\n",
      "\u001b[1;3;38;5;200mThought: The current language of the user is: Chinese. I need to use a tool to help me answer the question.\n",
      "Action: get_weather\n",
      "Action Input: {'city': 'NY'}\n",
      "\u001b[0m\u001b[1;3;34mObservation: 20\n",
      "\u001b[0m> Running step 04099a3a-2c96-4e2b-aa4d-1bfde8acf0b0. Step input: None\n",
      "\u001b[1;3;38;5;200mThought: I have obtained the weather information for New York, which is 20 degrees. Now I need to provide this information to the user.\n",
      "Answer: 纽约现在的天气是20度。\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "def get_weather(city: str) -> int:\n",
    "    \"\"\"\n",
    "    Gets the weather temperature of a specified city.\n",
    "\n",
    "    Args:\n",
    "    city (str): The name or abbreviation of the city.\n",
    "\n",
    "    Returns:\n",
    "    int: The temperature of the city. Returns 20 for 'NY' (New York),\n",
    "         30 for 'BJ' (Beijing), and -1 for unknown cities.\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert the input city to uppercase to handle case-insensitive comparisons\n",
    "    city = city.upper()\n",
    "\n",
    "    # Check if the city is New York ('NY')\n",
    "    if city == \"NY\":\n",
    "        return 20  # Return 20°C for New York\n",
    "\n",
    "    # Check if the city is Beijing ('BJ')\n",
    "    elif city == \"BJ\":\n",
    "        return 30  # Return 30°C for Beijing\n",
    "\n",
    "    # If the city is neither 'NY' nor 'BJ', return -1 to indicate unknown city\n",
    "    else:\n",
    "        return -1\n",
    "\n",
    "weather_tool = FunctionTool.from_defaults(fn=get_weather)\n",
    "\n",
    "agent = ReActAgent.from_tools([multiply_tool, add_tool, weather_tool], llm=llm, verbose=True)\n",
    "\n",
    "response = agent.chat(\"纽约天气怎么样?\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "meta",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
